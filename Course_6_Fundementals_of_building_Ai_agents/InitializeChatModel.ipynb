{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langchain-openai"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95t2H13m0VnJ",
        "outputId": "34d20e83-e440-4b1e-b903-cf1c92a49dd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.3.74)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.100.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ufMcbdQPzlW7"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key =userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "L6XFNyY30GNb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", api_key = api_key)"
      ],
      "metadata": {
        "id": "cktSjydaz2Bk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "\n",
        "  \"\"\"Add a and b \"\"\"\n",
        "  return a + b"
      ],
      "metadata": {
        "id": "JGw8ognT0cUD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def subtract(a: int, b: int) -> int:\n",
        "\n",
        "  \"\"\"Subtract b from a \"\"\"\n",
        "  return a - b"
      ],
      "metadata": {
        "id": "RHuWKOtt1BRS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "\n",
        "  \"\"\"Multiply a by b \"\"\"\n",
        "  return a * b"
      ],
      "metadata": {
        "id": "hQyHL2PR1m51"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_map = {\"add\": add, \"subtract\": subtract, \"multiply\": multiply}\n"
      ],
      "metadata": {
        "id": "i3jU7XWK13SQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = {\"a\": 1, \"b\": 2}\n",
        "tool_map[\"add\"].invoke(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzDCLAtK2KgR",
        "outputId": "1d6ee312-9410-42dc-afca-c5f2d9c2c22b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [add, subtract, multiply]\n",
        "llm_with_tools = llm.bind_tools(tools)\n"
      ],
      "metadata": {
        "id": "G9qHa2uc25Uh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_map[\"subtract\"].invoke(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNAsRvgd3LvK",
        "outputId": "40ac5a5e-de23-42da-c9e5-6f6b4aa978eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "query = \"What is 3 + 2?\"\n",
        "chat_history = [HumanMessage(content=query)]"
      ],
      "metadata": {
        "id": "CXWazv896RUA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Chat history before invoke:\", chat_history)\n",
        "response_1 = llm_with_tools.invoke(chat_history)\n",
        "chat_history.append(response_1)\n",
        "\n",
        "print(type(response_1))\n",
        "#print(response_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USwFFB6s6Ym3",
        "outputId": "62c70e03-de9f-4a29-addf-067eb7f28f42"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat history before invoke: [HumanMessage(content='What is 3 + 2?', additional_kwargs={}, response_metadata={})]\n",
            "<class 'langchain_core.messages.ai.AIMessage'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_calls_1 = response_1.tool_calls\n",
        "\n",
        "tool_1_name = tool_calls_1[0][\"name\"]\n",
        "tool_1_args = tool_calls_1[0][\"args\"]\n",
        "tool_call_1_id = tool_calls_1[0][\"id\"]\n",
        "\n",
        "print(f'tool name:\\n{tool_1_name}')\n",
        "print(f'tool args:\\n{tool_1_args}')\n",
        "print(f'tool call ID:\\n{tool_call_1_id}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bziKP88W6kGc",
        "outputId": "028d708a-787f-4d0e-c46e-a7fe4df4a8e3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tool name:\n",
            "add\n",
            "tool args:\n",
            "{'a': 3, 'b': 2}\n",
            "tool call ID:\n",
            "call_Xk1yYFpdUcYjf9rFLVhaBch8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "tool_response = tool_map[tool_1_name].invoke(tool_1_args)\n",
        "tool_message = ToolMessage(content=tool_response, tool_call_id=tool_call_1_id)\n",
        "\n",
        "print(tool_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hYIzN3z6l9o",
        "outputId": "64cf80e2-4ea9-4bb1-cc40-7902258850d4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='5' tool_call_id='call_Xk1yYFpdUcYjf9rFLVhaBch8'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history.append(tool_message)"
      ],
      "metadata": {
        "id": "L7C_VyKW63mx"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm_with_tools.invoke(chat_history)\n",
        "print(type(answer))\n",
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1CCZp7-65nm",
        "outputId": "8d7bd1ba-83c0-43f3-ca25-c091056c993c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.messages.ai.AIMessage'>\n",
            "3 + 2 equals 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ToolCallingAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm_with_tools = llm.bind_tools(tools)\n",
        "        self.tool_map = tool_map\n",
        "\n",
        "    def run(self, query: str) -> str:\n",
        "        # Step 1: Initial user message\n",
        "        chat_history = [HumanMessage(content=query)]\n",
        "\n",
        "        # Step 2: LLM chooses tool\n",
        "        response = self.llm_with_tools.invoke(chat_history)\n",
        "        if not response.tool_calls:\n",
        "            return response.content # Direct response, no tool needed\n",
        "        # Step 3: Handle first tool call\n",
        "        tool_call = response.tool_calls[0]\n",
        "        tool_name = tool_call[\"name\"]\n",
        "        tool_args = tool_call[\"args\"]\n",
        "        tool_call_id = tool_call[\"id\"]\n",
        "\n",
        "        # Step 4: Call tool manually\n",
        "        tool_result = self.tool_map[tool_name].invoke(tool_args)\n",
        "\n",
        "        # Step 5: Send result back to LLM\n",
        "        tool_message = ToolMessage(content=str(tool_result), tool_call_id=tool_call_id)\n",
        "        chat_history.extend([response, tool_message])\n",
        "\n",
        "        # Step 6: Final LLM result\n",
        "        final_response = self.llm_with_tools.invoke(chat_history)\n",
        "        return final_response.content"
      ],
      "metadata": {
        "id": "33xvuaVe7xdG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent = ToolCallingAgent(llm)\n",
        "\n",
        "print(my_agent.run(\"one plus 2\"))\n",
        "\n",
        "print(my_agent.run(\"one - 2\"))\n",
        "\n",
        "print(my_agent.run(\"three times two\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg7Bl5JX8E08",
        "outputId": "799b8382-3b53-4bd5-b615-d1d02b7b7e36"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One plus two equals three.\n",
            "The result of \\( 1 - 2 \\) is \\( -1 \\).\n",
            "Three times two is 6.\n"
          ]
        }
      ]
    }
  ]
}