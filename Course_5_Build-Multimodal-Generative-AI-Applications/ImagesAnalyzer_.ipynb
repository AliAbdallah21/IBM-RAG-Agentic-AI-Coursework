{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LzcJXu4yr9qv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "pip install openai requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "import os\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "KGzVG0batySa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "llama_key = userdata.get('Llama_Api_Key')\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=llama_key\n",
        ")\n",
        "\n",
        "model_name = \"meta-llama/llama-4-maverick\"\n",
        "# Wrap it into a helper function (like a \"model\" object)\n",
        "def run_model(messages):\n",
        "    return client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=messages,\n",
        "        max_tokens=300\n",
        "    )\n"
      ],
      "metadata": {
        "id": "qmUQNdKns9VJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model_response (encoded_image, user_query, assistant_prompt = \"You are a helpful assistant answer the following user query in 1 or 2 sentences\"):\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\" : \"user\",\n",
        "          \"content\": [\n",
        "              {\n",
        "                  \"type\":\"text\",\n",
        "                  \"text\":assistant_prompt+user_query\n",
        "              },\n",
        "              {\n",
        "                 \"type\":\"image_url\",\n",
        "                 \"image_url\":{\n",
        "                     \"url\":\"data:image/jpeg;base64,\"+encoded_image,\n",
        "\n",
        "                 }\n",
        "              }\n",
        "          ]\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  response = run_model(messages)\n",
        "  return response.choices[0].message.content\n",
        "  # print(response)"
      ],
      "metadata": {
        "id": "Z8hFkK8VujoU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_urls = [\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/4/47/PNG_transparency_demonstration_1.png\",\n",
        "]\n",
        "\n",
        "\n",
        "encoded_images = [base64.b64encode(requests.get(url).content).decode(\"utf-8\") for url in image_urls]\n",
        "\n",
        "for encoded_image in encoded_images:\n",
        "    response = generate_model_response(encoded_image, \"What is shown in this picture?\")\n",
        "    print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkhjhbERu7_C",
        "outputId": "15872083-e2d1-4d26-edf3-6739dded92e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image shows three colorful dice falling downwards against a blurred background with horizontal stripes. The dice are rendered in different colors- blue, red, and green.\n"
          ]
        }
      ]
    }
  ]
}